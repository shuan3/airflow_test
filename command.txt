mkdir airflow-local
cd airflow-local
use git bach
curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml'

mkdir ./dags ./logs ./plugins ./utils


echo -e "AIRFLOW_UID=$(id -u)\nAIRFLOW_GID=0" > .env

cat .env

docker-compose up airflow-init

docker-compose up
docker ps
docker build -t airflowtest .
 docker-compose down --volumes --rm all

docker-compose down --volumes --rmi all
docker-compose up -d 

https://towardsdatascience.com/run-airflow-docker-1b83a57616fb

python dags/dynamic_dags/generator.py


# if using docker file
docker-compose up --build
docker-compose up --up

docker compose -f docker-compose.yaml build
docker compose -f docker-compose.yaml up -d
# use yaml only
docker-compose up --up
#refresh in airflow schedule
airflow dags reserialize 


#Build image first then compose up
docker build . --tag ray/airflow:lastest
docker-compose up


git
git checkout -b ray/test origin/ray/test
git remote add origin/ray/test git@github.com:shuan3/airflow_test.git



  # image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.7.3}
  image: ${AIRFLOW_IMAGE_NAME:-ray/airflow:lastest}
  # build:
  #   context: .
  #   dockerfile: Dockerfile





  You have two FROM in your Dockerfile which is likely wrong (you do not seem to be using multi-segmented build). 
  You also use some SLUGIFY vars that were needed maybe 4 years ago and it looks like your Dockerfile is a bit messy and seems to be coming from slapped together
   solutions found in some random blogs. I suggest  that you start from scratch based on the examples 
   here https://airflow.apache.org/docs/docker-stack/build.html#examples-of-image-extending -  there are plenty of examples of 
   what you should do to extend the image and all of them are actually tested automatically in our CI as well,
   so it is quite likely that if you start with them and follow them, you will be able to avoid the kind of problem you have.